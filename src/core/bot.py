import logging
import asyncio
import os
import re
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta
from urllib.parse import urlparse

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, filters, ContextTypes
from telegram.constants import ParseMode

from .classifier import ContentClassifier
from .config import get_ai_config, TELEGRAM_BOT_TOKEN
from ..utils.storage import ResourceStorage
from ..utils.rate_limiter import RateLimiter
from ..utils.i18n import I18nManager
from ..handlers.file_handler import FileHandler
from ..handlers.message_sorter import MessageSorter

logger = logging.getLogger(__name__)

class DevDataSorterBot:
    """Main bot class for DevDataSorter."""
    
    def __init__(self, token: str = None):
        self.token = token or TELEGRAM_BOT_TOKEN
        self.ai_config = get_ai_config()
        self.storage = ResourceStorage()
        self.classifier = ContentClassifier()
        self.rate_limiter = RateLimiter()
        self.i18n = I18nManager()
        self.file_handler = FileHandler()
        self.message_sorter = MessageSorter(self.classifier)
        
        # Initialize Telegram application
        self.app = Application.builder().token(self.token).build()
        
        # Add handlers
        self._setup_handlers()
    
    def _setup_handlers(self):
        """Setup all bot handlers."""
        # Command handlers
        self.app.add_handler(CommandHandler("start", self.start_command))
        self.app.add_handler(CommandHandler("help", self.help_command))
        self.app.add_handler(CommandHandler("list", self.list_command))
        self.app.add_handler(CommandHandler("search", self.search_command))
        self.app.add_handler(CommandHandler("export", self.export_command))
        self.app.add_handler(CommandHandler("stats", self.stats_command))
        
        # New enhanced commands
        self.app.add_handler(CommandHandler("create_folder", self.create_folder_command))
        self.app.add_handler(CommandHandler("create_archive", self.create_archive_command))
        self.app.add_handler(CommandHandler("find_folder", self.find_folder_command))
        self.app.add_handler(CommandHandler("smart_search", self.smart_search_command))
        self.app.add_handler(CommandHandler("analyze", self.analyze_command))
        
        # Message handlers
        self.app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_message))
        self.app.add_handler(MessageHandler(filters.PHOTO, self.handle_photo))
        self.app.add_handler(MessageHandler(filters.Document.ALL, self.handle_document))
        
        # Callback query handler
        self.app.add_handler(CallbackQueryHandler(self.handle_callback_query))
    
    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /start command."""
        welcome_text = (
            "ü§ñ **DevDataSorter Bot** / –ë–æ—Ç –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n\n"
            "üìù **What I can do / –ß—Ç–æ —è —É–º–µ—é:**\n"
            "‚Ä¢ Classify and store your content / –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç\n"
            "‚Ä¢ Answer questions intelligently / –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã\n"
            "‚Ä¢ Search through saved resources / –ò—Å–∫–∞—Ç—å –ø–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–º —Ä–µ—Å—É—Ä—Å–∞–º\n"
            "‚Ä¢ Export your data / –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ\n\n"
            "üìã **Commands / –ö–æ–º–∞–Ω–¥—ã:**\n"
            "‚Ä¢ `/help` - Show help / –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É\n"
            "‚Ä¢ `/list [category]` - List resources / –°–ø–∏—Å–æ–∫ —Ä–µ—Å—É—Ä—Å–æ–≤\n"
            "‚Ä¢ `/search <query>` - Search resources / –ü–æ–∏—Å–∫ —Ä–µ—Å—É—Ä—Å–æ–≤\n"
            "‚Ä¢ `/export` - Export data / –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö\n"
            "‚Ä¢ `/stats` - Show statistics / –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n\n"
            "üí° **Just send me any content and I'll help organize it!**\n"
            "üí° **–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –ª—é–±–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç, –∏ —è –ø–æ–º–æ–≥—É –µ–≥–æ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å!**"
        )
        
        await update.message.reply_text(welcome_text, parse_mode=ParseMode.MARKDOWN)
    
    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /help command."""
        help_text = (
            "üÜò **Help / –°–ø—Ä–∞–≤–∫–∞**\n\n"
            "**üì§ Sending Content / –û—Ç–ø—Ä–∞–≤–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞:**\n"
            "‚Ä¢ Text messages / –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n"
            "‚Ä¢ Images with descriptions / –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏\n"
            "‚Ä¢ Documents (PDF, DOC, etc.) / –î–æ–∫—É–º–µ–Ω—Ç—ã\n"
            "‚Ä¢ URLs and links / URL –∏ —Å—Å—ã–ª–∫–∏\n\n"
            "**üîç Searching / –ü–æ–∏—Å–∫:**\n"
            "‚Ä¢ `/search python tutorial` - Find Python tutorials\n"
            "‚Ä¢ `/search –∫–∞—Ç–µ–≥–æ—Ä–∏—è:–∫–æ–¥` - Search in specific category\n\n"
            "**üìã Listing / –ü—Ä–æ—Å–º–æ—Ç—Ä:**\n"
            "‚Ä¢ `/list` - Show all resources / –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ —Ä–µ—Å—É—Ä—Å—ã\n"
            "‚Ä¢ `/list code` - Show code resources / –ü–æ–∫–∞–∑–∞—Ç—å –∫–æ–¥\n\n"
            "**üìä Other / –î—Ä—É–≥–æ–µ:**\n"
            "‚Ä¢ `/stats` - View statistics / –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "‚Ä¢ `/export` - Download your data / –°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ\n\n"
            "**ü§ñ AI Features / –ò–ò —Ñ—É–Ω–∫—Ü–∏–∏:**\n"
            "‚Ä¢ Ask questions / –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã\n"
            "‚Ä¢ Get explanations / –ü–æ–ª—É—á–∞–π—Ç–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è\n"
            "‚Ä¢ Request help / –ü—Ä–æ—Å–∏—Ç–µ –ø–æ–º–æ—â—å"
        )
        
        await update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)
    
    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle incoming text messages."""
        user_id = update.effective_user.id
        content = update.message.text
        
        # Rate limiting
        if not self.rate_limiter.is_allowed(user_id):
            await update.message.reply_text(
                "‚è∞ Too many requests. Please wait a moment.\n"
                "‚è∞ –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ."
            )
            return
        
        # Determine if this is a question/request or content to classify
        if await self._is_question_or_request(content):
            await self._handle_intelligent_response(update, context, content)
        else:
            await self._process_content(update, context, content)
    
    async def _is_question_or_request(self, content: str) -> bool:
        """Determine if content is a question or request for AI response."""
        content_lower = content.lower()
        
        # Question indicators
        question_words = [
            '—á—Ç–æ', '–∫–∞–∫', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–∫–∞–∫–æ–π', '–∫–∞–∫–∞—è', '–∫–∞–∫–æ–µ', '–∫–∞–∫–∏–µ',
            'what', 'how', 'where', 'when', 'why', 'which', 'who', 'whom', 'whose'
        ]
        
        # Request indicators
        request_words = [
            '–ø–æ–º–æ–≥–∏', '–ø–æ–º–æ—â—å', '–æ–±—ä—è—Å–Ω–∏', '—Ä–∞—Å—Å–∫–∞–∂–∏', '–ø–æ–∫–∞–∂–∏', '–Ω–∞–π–¥–∏', '–∏—â–∏',
            'help', 'explain', 'tell', 'show', 'find', 'search', 'look'
        ]
        
        # Check for question marks
        if '?' in content:
            return True
        
        # Check for question/request words
        words = content_lower.split()
        if any(word in question_words + request_words for word in words):
            return True
        
        # Check for question patterns
        question_patterns = [
            r'^(—á—Ç–æ|–∫–∞–∫|–≥–¥–µ|–∫–æ–≥–¥–∞|–ø–æ—á–µ–º—É|–∑–∞—á–µ–º)',
            r'^(what|how|where|when|why|which)',
            r'(–º–æ–∂–µ—à—å|–º–æ–∂–µ—Ç–µ|could you|can you)',
            r'(–ø–æ–º–æ–≥–∏|help me|–ø–æ–º–æ—â—å|assistance)'
        ]
        
        for pattern in question_patterns:
            if re.search(pattern, content_lower):
                return True
        
        return False
    
    async def _handle_intelligent_response(self, update: Update, context: ContextTypes.DEFAULT_TYPE, content: str):
        """Handle intelligent AI responses to questions and requests."""
        try:
            # Show typing indicator
            await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")
            
            # Determine response type
            response_type = await self._determine_response_type(content)
            
            # Show appropriate indicator based on type
            if response_type == 'search':
                status_msg = await update.message.reply_text("üîç Searching / –ü–æ–∏—Å–∫...")
            elif response_type == 'help':
                status_msg = await update.message.reply_text("üí° Thinking / –î—É–º–∞—é...")
            elif response_type == 'technical':
                status_msg = await update.message.reply_text("üîß Analyzing / –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...")
            else:
                status_msg = await update.message.reply_text("ü§ñ Processing / –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é...")
            
            # Check if this is a search request
            if await self._is_search_request(content):
                await self._handle_search_from_message(update, context, content)
                await status_msg.delete()
                return
            
            # Generate AI response
            ai_response = await self.classifier.generate_response(content)
            
            if ai_response:
                # Format response based on type
                formatted_response = await self._format_intelligent_response(ai_response, response_type, content)
                
                # Delete status message and send response
                await status_msg.delete()
                await update.message.reply_text(formatted_response, parse_mode=ParseMode.MARKDOWN)
            else:
                # Fallback response
                fallback_response = await self._generate_fallback_response(content, response_type)
                await status_msg.delete()
                await update.message.reply_text(fallback_response, parse_mode=ParseMode.MARKDOWN)
                
        except Exception as e:
            logger.error(f"Error in intelligent response: {e}")
            await update.message.reply_text(
                "‚ùå Sorry, I couldn't process your request right now.\n"
                "‚ùå –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –º–æ–≥—É –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∞—à –∑–∞–ø—Ä–æ—Å –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å."
            )
    
    async def _determine_response_type(self, content: str) -> str:
        """Determine the type of response needed based on content analysis."""
        content_lower = content.lower()
        
        # Search indicators
        if await self._is_search_request(content):
            return 'search'
        
        # Help/guidance indicators
        help_indicators = [
            '–ø–æ–º–æ–≥–∏', '–ø–æ–º–æ—â—å', '–∫–∞–∫', '—á—Ç–æ –¥–µ–ª–∞—Ç—å', '–Ω–µ –∑–Ω–∞—é', '–æ–±—ä—è—Å–Ω–∏', '—Ä–∞—Å—Å–∫–∞–∂–∏',
            'help', 'how to', 'what should', 'explain', 'tell me', 'guide', 'tutorial'
        ]
        if any(indicator in content_lower for indicator in help_indicators):
            return 'help'
        
        # Technical/programming indicators
        tech_indicators = [
            '–∫–æ–¥', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '–∞–ª–≥–æ—Ä–∏—Ç–º', '—Ñ—É–Ω–∫—Ü–∏—è', '–∫–ª–∞—Å—Å', '–±–∏–±–ª–∏–æ—Ç–µ–∫–∞', '—Ñ—Ä–µ–π–º–≤–æ—Ä–∫',
            'code', 'programming', 'algorithm', 'function', 'class', 'library', 'framework',
            'python', 'javascript', 'java', 'c++', 'react', 'node', 'api', 'database'
        ]
        if any(indicator in content_lower for indicator in tech_indicators):
            return 'technical'
        
        # Default to general
        return 'general'
    
    async def _format_intelligent_response(self, ai_response: str, response_type: str, original_content: str) -> str:
        """Format AI response based on response type and content."""
        # Choose appropriate emoji and title based on type
        type_config = {
            'search': {'emoji': 'üîç', 'title': '–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ / Search Result'},
            'help': {'emoji': 'üí°', 'title': '–°–ø—Ä–∞–≤–∫–∞ / Help'},
            'technical': {'emoji': 'üîß', 'title': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è / Technical Info'},
            'general': {'emoji': 'ü§ñ', 'title': 'AI –û—Ç–≤–µ—Ç / AI Response'}
        }
        
        config = type_config.get(response_type, type_config['general'])
        
        # Format the main response
        formatted_response = f"{config['emoji']} **{config['title']}:**\n\n{ai_response}\n\n"
        
        # Add contextual footer based on response type
        if response_type == 'technical':
            formatted_response += "üíæ *–•–æ—Ç–∏—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç—Ç–æ—Ç –∫–æ–¥/–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é? –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ–≥–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º*\n"
            formatted_response += "üíæ *Want to save this code/info? Send it as a separate message*"
        elif response_type == 'help':
            formatted_response += "üìö *–ù—É–∂–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–º–æ—â—å? –ó–∞–¥–∞–π—Ç–µ —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å*\n"
            formatted_response += "üìö *Need more help? Ask a follow-up question*"
        else:
            formatted_response += "üí° *–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç—Ç–æ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –µ–≥–æ –µ—â–µ —Ä–∞–∑*\n"
            formatted_response += "üí° *If you wanted to save this content, send it again*"
        
        return formatted_response
    
    async def _generate_fallback_response(self, content: str, response_type: str) -> str:
        """Generate fallback response when AI is unavailable."""
        fallback_responses = {
            'search': (
                "üîç **Search functionality temporarily unavailable**\n\n"
                "Try using `/search <your query>` command instead.\n\n"
                "üîç **–ü–æ–∏—Å–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω**\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É `/search <–≤–∞—à –∑–∞–ø—Ä–æ—Å>`."
            ),
            'help': (
                "üí° **Help system temporarily unavailable**\n\n"
                "Please check `/help` command for basic information.\n\n"
                "üí° **–°–∏—Å—Ç–µ–º–∞ –ø–æ–º–æ—â–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞**\n\n"
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É `/help` –¥–ª—è –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
            ),
            'technical': (
                "üîß **Technical analysis temporarily unavailable**\n\n"
                "You can still save your content by sending it again.\n\n"
                "üîß **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω**\n\n"
                "–í—ã –º–æ–∂–µ—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç, –æ—Ç–ø—Ä–∞–≤–∏–≤ –µ–≥–æ –µ—â–µ —Ä–∞–∑."
            ),
            'general': (
                "ü§ñ **AI response temporarily unavailable**\n\n"
                "I can still help you organize and save content!\n\n"
                "ü§ñ **–ò–ò –æ—Ç–≤–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω**\n\n"
                "–Ø –≤—Å–µ –µ—â–µ –º–æ–≥—É –ø–æ–º–æ—á—å –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç!"
            )
        }
        
        return fallback_responses.get(response_type, fallback_responses['general'])
    
    async def _process_content(self, update: Update, context: ContextTypes.DEFAULT_TYPE, content: str):
        """Process and classify content for storage."""
        try:
            # Preprocess content
            processed_content = await self._preprocess_content(content)
            
            # Extract URLs
            urls = self._extract_urls(processed_content)
            
            # Classify content with enhanced logic
            classification = await self.classifier.classify_content(processed_content)
            
            if not classification:
                # Enhanced fallback classification
                classification = await self._enhanced_fallback_classification(processed_content)
            
            if classification:
                # Prepare additional data
                additional_data = {
                    'urls': urls,
                    'timestamp': datetime.now().isoformat(),
                    'user_id': update.effective_user.id,
                    'message_id': update.message.message_id
                }
                
                # Add resource to storage
                resource_id = self.storage.add_resource(
                    content=processed_content,
                    category=classification['category'],
                    user_id=update.effective_user.id,
                    username=update.effective_user.username,
                    description=classification['description'],
                    urls=urls
                )
                
                # Format success message
                success_message = (
                    f"‚úÖ **Content classified and saved!**\n\n"
                    f"üìÇ **Category:** {classification['category']}\n"
                    f"üìù **Description:** {classification['description']}\n"
                    f"üÜî **ID:** {resource_id}\n"
                )
                
                if urls:
                    success_message += f"üîó **URLs found:** {len(urls)}\n"
                
                success_message += (
                    f"\n‚úÖ **–ö–æ–Ω—Ç–µ–Ω—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω!**\n"
                    f"üìÇ **–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** {classification['category']}\n"
                    f"üìù **–û–ø–∏—Å–∞–Ω–∏–µ:** {classification['description']}"
                )
                
                await update.message.reply_text(success_message, parse_mode=ParseMode.MARKDOWN)
            else:
                await update.message.reply_text(
                    "‚ùå Unable to classify content. Please try rephrasing or adding more context.\n"
                    "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
                )
                
        except Exception as e:
            logger.error(f"Error processing content: {e}")
            await update.message.reply_text(
                "‚ùå Error processing content. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
    
    async def _preprocess_content(self, content: str) -> str:
        """Preprocess content before classification."""
        # Remove extra whitespace
        content = ' '.join(content.split())
        
        # Add URL context if URLs are present
        urls = self._extract_urls(content)
        if urls:
            url_context = f"\n\nURLs: {', '.join(urls)}"
            content += url_context
        
        # Detect and add technical content context
        if self._is_technical_content(content):
            content = f"[TECHNICAL CONTENT] {content}"
        
        return content
    
    def _is_technical_content(self, content: str) -> bool:
        """Detect if content is technical/programming related."""
        technical_indicators = [
            'function', 'class', 'import', 'export', 'const', 'let', 'var',
            'def', 'return', 'if', 'else', 'for', 'while', 'try', 'catch',
            'async', 'await', 'promise', 'callback', 'api', 'endpoint',
            'database', 'sql', 'query', 'select', 'insert', 'update',
            'git', 'commit', 'push', 'pull', 'merge', 'branch',
            'docker', 'kubernetes', 'deployment', 'server', 'client'
        ]
        
        content_lower = content.lower()
        return any(indicator in content_lower for indicator in technical_indicators)
    
    async def _enhanced_fallback_classification(self, content: str) -> Optional[Dict[str, Any]]:
        """Enhanced fallback classification with AI assistance."""
        try:
            # Try AI-assisted classification
            ai_classification = await self.classifier.classify_with_ai(content)
            if ai_classification:
                return ai_classification
        except Exception as e:
            logger.warning(f"AI classification failed: {e}")
        
        # Fallback to pattern-based classification
        return self._pattern_based_classification(content)
    
    def _pattern_based_classification(self, content: str) -> Optional[Dict[str, Any]]:
        """Pattern-based classification as final fallback."""
        content_lower = content.lower()
        
        # Define patterns for different categories
        patterns = {
            'code': ['function', 'class', 'import', 'def', 'return', 'var', 'const', 'let'],
            'documentation': ['readme', 'docs', 'documentation', 'guide', 'tutorial', 'how to'],
            'link': ['http', 'https', 'www.', '.com', '.org', '.net'],
            'note': ['note', 'remember', 'important', 'todo', 'task'],
            'question': ['?', 'how', 'what', 'why', 'when', 'where']
        }
        
        # Score each category
        scores = {}
        for category, keywords in patterns.items():
            score = sum(1 for keyword in keywords if keyword in content_lower)
            if score > 0:
                scores[category] = score
        
        if scores:
            # Get category with highest score
            best_category = max(scores, key=scores.get)
            return {
                'category': best_category,
                'description': f"Auto-classified as {best_category} based on content patterns",
                'confidence': min(scores[best_category] / len(patterns[best_category]), 1.0)
            }
        
        return None
    
    def _extract_urls(self, text: str) -> List[str]:
        """Extract URLs from text."""
        url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
        return re.findall(url_pattern, text)
    
    async def _is_search_request(self, content: str) -> bool:
        """Determine if content is a search request."""
        content_lower = content.lower()
        
        # Extended search keywords
        search_keywords = [
            '–Ω–∞–π–¥–∏', '–Ω–∞–π—Ç–∏', '–ø–æ–∏—Å–∫', '–∏—â–∏', '–∏—Å–∫–∞—Ç—å', '–ø–æ–∫–∞–∂–∏', '–ø–æ–∫–∞–∑–∞—Ç—å',
            'find', 'search', 'look', 'show', 'get', 'retrieve', 'fetch',
            '–≥–¥–µ', 'where', '–µ—Å—Ç—å –ª–∏', 'is there', 'do you have'
        ]
        
        # Question patterns that indicate search
        search_patterns = [
            r'(–Ω–∞–π–¥–∏|find|search)\s+',
            r'(–≥–¥–µ|where)\s+.*\?',
            r'(–µ—Å—Ç—å –ª–∏|is there|do you have)\s+',
            r'(–ø–æ–∫–∞–∂–∏|show me)\s+'
        ]
        
        # Check for search keywords
        words = content_lower.split()
        if any(keyword in words for keyword in search_keywords):
            return True
        
        # Check for search patterns
        for pattern in search_patterns:
            if re.search(pattern, content_lower):
                return True
        
        return False
    
    async def _handle_search_from_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE, content: str):
        """Handle search request from a message."""
        # Extract search terms
        search_terms = self._extract_search_terms(content)
        
        if search_terms:
            # Perform search
            results = self.storage.search_resources(' '.join(search_terms))
            
            if results:
                response = f"üîç **Search Results for '{' '.join(search_terms)}':**\n\n"
                
                for i, result in enumerate(results[:5], 1):
                    response += (
                        f"{i}. **{result['category']}** - {result['description'][:100]}...\n"
                        f"   üÜî ID: {result['id']}\n\n"
                    )
                
                if len(results) > 5:
                    response += f"... and {len(results) - 5} more results\n\n"
                
                response += "üîç **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞:**\n"
                response += f"–ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
                
                await update.message.reply_text(response, parse_mode=ParseMode.MARKDOWN)
            else:
                await update.message.reply_text(
                    f"‚ùå No results found for '{' '.join(search_terms)}'.\n"
                    f"‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{' '.join(search_terms)}'."
                )
        else:
            await update.message.reply_text(
                "‚ùå Couldn't understand what to search for. Please clarify.\n"
                "‚ùå –ù–µ –ø–æ–Ω—è–ª, —á—Ç–æ –∏—Å–∫–∞—Ç—å. –£—Ç–æ—á–Ω–∏—Ç–µ –∑–∞–ø—Ä–æ—Å."
            )
    
    def _extract_search_terms(self, content: str) -> List[str]:
        """Extract search terms from content."""
        # Remove common search words
        stop_words = {
            '–Ω–∞–π–¥–∏', '–Ω–∞–π—Ç–∏', '–ø–æ–∏—Å–∫', '–∏—â–∏', '–∏—Å–∫–∞—Ç—å', '–ø–æ–∫–∞–∂–∏', '–ø–æ–∫–∞–∑–∞—Ç—å',
            'find', 'search', 'look', 'show', 'get', 'retrieve', 'fetch',
            '–≥–¥–µ', 'where', '–µ—Å—Ç—å', '–ª–∏', 'is', 'there', 'do', 'you', 'have',
            '–º–Ω–µ', 'me', '–¥–ª—è', 'for', '–ø–æ', 'about', '–ø—Ä–æ', '–æ'
        }
        
        words = content.lower().split()
        search_terms = [word for word in words if word not in stop_words and len(word) > 2]
        
        return search_terms
    
    async def list_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /list command."""
        try:
            # Get category filter if provided
            category_filter = None
            if context.args:
                category_filter = ' '.join(context.args).lower()
            
            # Get resources
            if category_filter:
                resources = self.storage.get_resources_by_category(category_filter)
            else:
                resources = self.storage.get_all_resources()
            
            if resources:
                if category_filter:
                    response = f"üìÇ **Resources in category '{category_filter}':**\n\n"
                else:
                    response = "üìÇ **All saved resources:**\n\n"
                
                for i, resource in enumerate(resources[:10], 1):
                    response += (
                        f"{i}. **{resource['category']}** - {resource['description'][:80]}...\n"
                        f"   üÜî ID: {resource['id']} | üìÖ {resource['created_at'][:10]}\n\n"
                    )
                
                if len(resources) > 10:
                    response += f"... and {len(resources) - 10} more resources\n\n"
                
                response += f"üìä Total: {len(resources)} resources"
                
                await update.message.reply_text(response, parse_mode=ParseMode.MARKDOWN)
            else:
                if category_filter:
                    await update.message.reply_text(
                        f"üìÇ No resources in category '{category_filter}'.\n"
                        f"üìÇ –ù–µ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category_filter}'."
                    )
                else:
                    await update.message.reply_text(
                        "üìÇ No saved resources yet.\n"
                        "üìÇ –ü–æ–∫–∞ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤."
                    )
                    
        except Exception as e:
            logger.error(f"Error in list command: {e}")
            await update.message.reply_text(
                "‚ùå Error retrieving resources.\n"
                "‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤."
            )
    
    async def search_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /search command."""
        if not context.args:
            await update.message.reply_text(
                "üîç **Usage:** `/search <query>`\n"
                "üîç **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** `/search <–∑–∞–ø—Ä–æ—Å>`\n\n"
                "**Examples / –ü—Ä–∏–º–µ—Ä—ã:**\n"
                "‚Ä¢ `/search python tutorial`\n"
                "‚Ä¢ `/search –∫–∞—Ç–µ–≥–æ—Ä–∏—è:–∫–æ–¥`"
            )
            return
        
        query = ' '.join(context.args)
        
        try:
            results = self.storage.search_resources(query)
            
            if results:
                response = f"üîç **Search Results for '{query}':**\n\n"
                
                for i, result in enumerate(results[:10], 1):
                    response += (
                        f"{i}. **{result['category']}** - {result['description'][:100]}...\n"
                        f"   üÜî ID: {result['id']} | üìÖ {result['created_at'][:10]}\n\n"
                    )
                
                if len(results) > 10:
                    response += f"... and {len(results) - 10} more results\n\n"
                
                response += f"üìä Found {len(results)} results"
                
                await update.message.reply_text(response, parse_mode=ParseMode.MARKDOWN)
            else:
                await update.message.reply_text(
                    f"‚ùå No results found for '{query}'.\n"
                    f"‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}'."
                )
                
        except Exception as e:
            logger.error(f"Error in search command: {e}")
            await update.message.reply_text(
                "‚ùå Search error. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
    
    async def stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /stats command."""
        try:
            stats = self.storage.get_statistics()
            
            response = (
                "üìä **Statistics / –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**\n\n"
                f"üìÇ **Total resources / –í—Å–µ–≥–æ —Ä–µ—Å—É—Ä—Å–æ–≤:** {stats.get('total_resources', 0)}\n"
                f"üè∑Ô∏è **Categories / –ö–∞—Ç–µ–≥–æ—Ä–∏–π:** {stats.get('total_categories', 0)}\n"
                f"üìÖ **This week / –ó–∞ –Ω–µ–¥–µ–ª—é:** {stats.get('resources_this_week', 0)}\n"
                f"üìà **This month / –ó–∞ –º–µ—Å—è—Ü:** {stats.get('resources_this_month', 0)}\n\n"
            )
            
            # Top categories
            if 'top_categories' in stats:
                response += "üîù **Top categories / –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:**\n"
                for category, count in stats['top_categories'][:5]:
                    response += f"‚Ä¢ {category}: {count}\n"
            
            await update.message.reply_text(response, parse_mode=ParseMode.MARKDOWN)
            
        except Exception as e:
            logger.error(f"Error in stats command: {e}")
            await update.message.reply_text(
                "‚ùå Error retrieving statistics.\n"
                "‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏."
            )
    
    async def export_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /export command."""
        try:
            # Get all resources
            all_resources = self.storage.get_all_resources()
            
            if not all_resources:
                await update.message.reply_text(
                    "üìÇ No data to export.\n"
                    "üìÇ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞."
                )
                return
            
            # Create export data
            export_data = {
                'export_date': datetime.now().isoformat(),
                'total_resources': len(all_resources),
                'resources': all_resources
            }
            
            # Convert to JSON
            import json
            json_data = json.dumps(export_data, indent=2, ensure_ascii=False)
            
            # Create file
            filename = f"devdatasorter_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            # Send as document
            from io import BytesIO
            file_buffer = BytesIO(json_data.encode('utf-8'))
            file_buffer.name = filename
            
            # Get categories for summary
            categories = set(resource['category'] for resource in all_resources)
            
            await update.message.reply_document(
                document=file_buffer,
                caption=f"üì§ Data export / –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö\nüìä Resources: {len(all_resources)}\nüìÇ Categories: {len(categories)}"
            )
            
        except Exception as e:
            logger.error(f"Error in export command: {e}")
            await update.message.reply_text(
                "‚ùå Export error. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
    
    async def handle_photo(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle photo messages."""
        try:
            # Get photo and caption
            photo = update.message.photo[-1]  # Get highest resolution
            caption = update.message.caption or "Image without description"
            
            # Download photo
            file = await context.bot.get_file(photo.file_id)
            file_path = f"temp_image_{photo.file_id}.jpg"
            await file.download_to_drive(file_path)
            
            try:
                # Process image with file handler
                image_analysis = await self.file_handler.process_image(file_path, caption)
                
                # Combine caption and analysis
                content = f"{caption}\n\nImage analysis: {image_analysis}"
                
                # Process as regular content
                await self._process_content(update, context, content)
                
            finally:
                # Clean up
                if os.path.exists(file_path):
                    os.remove(file_path)
                    
        except Exception as e:
            logger.error(f"Error handling photo: {e}")
            await update.message.reply_text(
                "‚ùå Failed to process image / –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
            )
    
    async def handle_document(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle document messages."""
        try:
            document = update.message.document
            caption = update.message.caption or "Document without description"
            
            # Check file size (limit to 20MB)
            if document.file_size > 20 * 1024 * 1024:
                await update.message.reply_text(
                    "‚ùå File too large (max 20MB) / –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å 20–ú–ë)"
                )
                return
            
            # Download document
            file = await context.bot.get_file(document.file_id)
            file_path = f"temp_doc_{document.file_id}_{document.file_name}"
            await file.download_to_drive(file_path)
            
            try:
                # Process document with file handler
                doc_analysis = await self.file_handler.process_document(file_path, caption)
                
                # Combine caption and analysis
                content = f"{caption}\n\nDocument: {document.file_name}\nSize: {document.file_size} bytes\nAnalysis: {doc_analysis}"
                
                # Process as regular content
                await self._process_content(update, context, content)
                
            finally:
                # Clean up
                if os.path.exists(file_path):
                    os.remove(file_path)
                    
        except Exception as e:
            logger.error(f"Error handling document: {e}")
            await update.message.reply_text(
                "‚ùå Failed to process document / –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç"
            )
    
    async def handle_callback_query(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle callback queries from inline keyboards."""
        query = update.callback_query
        await query.answer()
        
        # Handle different callback types
        if query.data.startswith('view_'):
            resource_id = query.data.split('_')[1]
            await self._show_resource_details(query, resource_id)
        elif query.data.startswith('delete_'):
            resource_id = query.data.split('_')[1]
            await self._delete_resource(query, resource_id)
    
    async def _show_resource_details(self, query, resource_id: str):
        """Show detailed information about a resource."""
        try:
            resource = self.storage.get_resource(resource_id)
            if resource:
                response = (
                    f"üìÑ **Resource Details:**\n\n"
                    f"üÜî **ID:** {resource['id']}\n"
                    f"üìÇ **Category:** {resource['category']}\n"
                    f"üìù **Description:** {resource['description']}\n"
                    f"üìÖ **Created:** {resource['created_at']}\n\n"
                    f"üìÑ **Content:**\n{resource['content'][:500]}..."
                )
                
                await query.edit_message_text(response, parse_mode=ParseMode.MARKDOWN)
            else:
                await query.edit_message_text("‚ùå Resource not found")
                
        except Exception as e:
            logger.error(f"Error showing resource details: {e}")
            await query.edit_message_text("‚ùå Error retrieving resource")
    
    async def _delete_resource(self, query, resource_id: str):
        """Delete a resource."""
        try:
            success = self.storage.delete_resource(resource_id)
            if success:
                await query.edit_message_text("‚úÖ Resource deleted successfully")
            else:
                await query.edit_message_text("‚ùå Failed to delete resource")
                
        except Exception as e:
            logger.error(f"Error deleting resource: {e}")
            await query.edit_message_text("‚ùå Error deleting resource")
    
    async def _smart_select_resources_for_archive(self, archive_name: str) -> list:
        """Smart selection of resources for archive based on name."""
        try:
            # Extract keywords from archive name
            keywords = archive_name.lower().replace('_', ' ').split()
            
            # Search for relevant resources
            all_resources = self.storage.get_all_resources()
            selected = []
            
            for resource in all_resources:
                score = 0
                content_lower = resource['content'].lower()
                desc_lower = resource['description'].lower()
                category_lower = resource['category'].lower()
                
                # Score based on keyword matches
                for keyword in keywords:
                    if keyword in content_lower:
                        score += 3
                    if keyword in desc_lower:
                        score += 2
                    if keyword in category_lower:
                        score += 4
                
                # Include if score is high enough
                if score >= 2:
                    selected.append(resource['id'])
            
            # Limit to 20 most recent if too many
            if len(selected) > 20:
                selected = selected[-20:]
            
            return selected
            
        except Exception as e:
            logger.error(f"Error in smart resource selection: {e}")
            return []
    
    async def _enhance_search_query(self, query: str) -> dict:
        """Use AI to enhance and understand search query."""
        try:
            # Create enhanced prompt for query understanding
            prompt = f"""
Analyze this search query and extract key information:
Query: "{query}"

Provide a JSON response with:
{{
    "keywords": ["list", "of", "key", "terms"],
    "categories": ["relevant", "categories"],
    "technologies": ["mentioned", "technologies"],
    "intent": "what user is looking for",
    "language": "detected language (en/ru)",
    "filters": {{
        "file_types": ["if", "specific", "types"],
        "difficulty": "beginner/intermediate/advanced or null",
        "recency": "recent/old or null"
    }}
}}

Focus on web development, design, programming topics.
"""
            
            # Try to get AI enhancement
            if self.classifier.groq_client:
                response = await self.classifier._call_groq_api(prompt)
                if response and 'keywords' in response:
                    return response
            
            # Fallback to simple keyword extraction
            return {
                "keywords": query.lower().split(),
                "categories": [],
                "technologies": self._extract_technologies_from_text(query),
                "intent": "search",
                "language": "ru" if any(ord(c) > 127 for c in query) else "en",
                "filters": {}
            }
            
        except Exception as e:
            logger.error(f"Error enhancing search query: {e}")
            return {"keywords": query.lower().split(), "categories": [], "technologies": [], "intent": "search", "language": "en", "filters": {}}
    
    async def _perform_smart_search(self, enhanced_query: dict) -> list:
        """Perform enhanced search using AI-processed query."""
        try:
            all_resources = self.storage.get_all_resources()
            scored_results = []
            
            keywords = enhanced_query.get('keywords', [])
            categories = enhanced_query.get('categories', [])
            technologies = enhanced_query.get('technologies', [])
            
            for resource in all_resources:
                score = 0
                content_lower = resource['content'].lower()
                desc_lower = resource['description'].lower()
                category_lower = resource['category'].lower()
                
                # Keyword matching
                for keyword in keywords:
                    if keyword in content_lower:
                        score += 2
                    if keyword in desc_lower:
                        score += 3
                    if keyword in category_lower:
                        score += 4
                
                # Category matching
                for category in categories:
                    if category.lower() in category_lower:
                        score += 5
                
                # Technology matching
                for tech in technologies:
                    if tech.lower() in content_lower or tech.lower() in desc_lower:
                        score += 3
                
                # URL bonus for web development content
                if any(url_indicator in content_lower for url_indicator in ['http', 'www', '.com', '.org', 'github']):
                    score += 1
                
                if score > 0:
                    # Calculate relevance score (0-10)
                    relevance = min(10, score)
                    
                    result = resource.copy()
                    result['relevance_score'] = relevance
                    scored_results.append(result)
            
            # Sort by relevance score
            scored_results.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            return scored_results
            
        except Exception as e:
            logger.error(f"Error in smart search: {e}")
            return []
    
    async def _perform_content_analysis(self) -> dict:
        """Perform comprehensive analysis of stored content."""
        try:
            all_resources = self.storage.get_all_resources()
            folders = self.storage.get_all_folders()
            archives = self.storage.get_all_archives()
            
            # Basic statistics
            analysis = {
                'total_resources': len(all_resources),
                'total_categories': len(set(r['category'] for r in all_resources)),
                'total_folders': len(folders),
                'total_archives': len(archives)
            }
            
            # Category analysis
            category_counts = {}
            for resource in all_resources:
                category = resource['category']
                category_counts[category] = category_counts.get(category, 0) + 1
            
            analysis['top_categories'] = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)
            
            # Technology analysis
            tech_counts = {}
            tech_patterns = {
                'React': ['react', 'jsx', 'hooks'],
                'Vue': ['vue', 'vuejs'],
                'Angular': ['angular', 'typescript'],
                'Python': ['python', 'django', 'flask'],
                'JavaScript': ['javascript', 'js', 'node'],
                'CSS': ['css', 'sass', 'scss'],
                'HTML': ['html', 'html5'],
                'Docker': ['docker', 'container'],
                'Git': ['git', 'github', 'gitlab'],
                'API': ['api', 'rest', 'graphql'],
                'Database': ['sql', 'mongodb', 'postgres'],
                'Design': ['figma', 'sketch', 'ui', 'ux']
            }
            
            for resource in all_resources:
                content_lower = resource['content'].lower()
                for tech, patterns in tech_patterns.items():
                    if any(pattern in content_lower for pattern in patterns):
                        tech_counts[tech] = tech_counts.get(tech, 0) + 1
            
            analysis['technologies'] = sorted(tech_counts.items(), key=lambda x: x[1], reverse=True)
            
            # Generate recommendations
            recommendations = []
            
            if analysis['total_resources'] > 50:
                recommendations.append("Consider creating more specific folders to organize your resources")
            
            if len(analysis['top_categories']) > 10:
                recommendations.append("You have many categories - consider consolidating similar ones")
            
            if any(count > 20 for _, count in analysis['top_categories'][:3]):
                recommendations.append("Create archives for your most popular categories")
            
            analysis['recommendations'] = recommendations
            
            return analysis
            
        except Exception as e:
            logger.error(f"Error in content analysis: {e}")
            return {'total_resources': 0, 'total_categories': 0, 'total_folders': 0, 'total_archives': 0}
    
    def _extract_technologies_from_text(self, text: str) -> list:
        """Extract technology names from text."""
        technologies = []
        text_lower = text.lower()
        
        tech_keywords = {
            'react', 'vue', 'angular', 'python', 'javascript', 'typescript',
            'css', 'html', 'sass', 'scss', 'node', 'express', 'django',
            'flask', 'docker', 'kubernetes', 'git', 'github', 'api', 'rest',
            'graphql', 'sql', 'mongodb', 'postgres', 'figma', 'sketch',
            'photoshop', 'illustrator', 'ui', 'ux', 'design', 'frontend',
            'backend', 'fullstack', 'mobile', 'ios', 'android', 'swift',
            'kotlin', 'java', 'c++', 'c#', 'php', 'ruby', 'go', 'rust'
        }
        
        for tech in tech_keywords:
            if tech in text_lower:
                technologies.append(tech.capitalize())
        
        return list(set(technologies))
    
    async def _delete_resource(self, query, resource_id: str):
        """Delete a resource."""
        try:
            success = self.storage.delete_resource(resource_id)
            if success:
                await query.edit_message_text("‚úÖ Resource deleted successfully")
            else:
                await query.edit_message_text("‚ùå Failed to delete resource")
                
        except Exception as e:
            logger.error(f"Error deleting resource: {e}")
            await query.edit_message_text("‚ùå Error deleting resource")
    
    def run(self):
        """Start the bot."""
        logger.info("Starting DevDataSorter bot...")
        try:
            # Create event loop if it doesn't exist
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        self.app.run_polling(drop_pending_updates=True)
        logger.info("Bot stopped")

    async def create_folder_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Create a virtual folder for organizing resources."""
        if not context.args:
            await update.message.reply_text(
                "üìÅ **Usage:** `/create_folder <folder_name> [description]`\n"
                "üìÅ **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** `/create_folder <–∏–º—è_–ø–∞–ø–∫–∏> [–æ–ø–∏—Å–∞–Ω–∏–µ]`\n\n"
                "**Examples / –ü—Ä–∏–º–µ—Ä—ã:**\n"
                "‚Ä¢ `/create_folder react_projects React –ø—Ä–æ–µ–∫—Ç—ã –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã`\n"
                "‚Ä¢ `/create_folder design_resources UI/UX –¥–∏–∑–∞–π–Ω —Ä–µ—Å—É—Ä—Å—ã`"
            )
            return
        
        folder_name = context.args[0]
        description = ' '.join(context.args[1:]) if len(context.args) > 1 else f"–ü–∞–ø–∫–∞ –¥–ª—è {folder_name}"
        
        try:
            # Create folder as a special resource
            folder_id = self.storage.create_folder(
                name=folder_name,
                description=description,
                user_id=update.effective_user.id,
                username=update.effective_user.username
            )
            
            await update.message.reply_text(
                f"üìÅ **Folder created successfully!**\n\n"
                f"üìÇ **Name:** {folder_name}\n"
                f"üìù **Description:** {description}\n"
                f"üÜî **ID:** {folder_id}\n\n"
                f"üìÅ **–ü–∞–ø–∫–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!**\n"
                f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `/add_to_folder {folder_id}` –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤",
                parse_mode=ParseMode.MARKDOWN
            )
            
        except Exception as e:
            logger.error(f"Error creating folder: {e}")
            await update.message.reply_text(
                "‚ùå Error creating folder. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–ø–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
    
    async def create_archive_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Create an archive from selected resources."""
        if not context.args:
            await update.message.reply_text(
                "üì¶ **Usage:** `/create_archive <archive_name> [resource_ids...]`\n"
                "üì¶ **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** `/create_archive <–∏–º—è_–∞—Ä—Ö–∏–≤–∞> [id_—Ä–µ—Å—É—Ä—Å–æ–≤...]`\n\n"
                "**Examples / –ü—Ä–∏–º–µ—Ä—ã:**\n"
                "‚Ä¢ `/create_archive web_dev_2024 abc123 def456 ghi789`\n"
                "‚Ä¢ `/create_archive react_components` (—Å–æ–∑–¥–∞—Å—Ç –∞—Ä—Ö–∏–≤ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö React —Ä–µ—Å—É—Ä—Å–æ–≤)"
            )
            return
        
        archive_name = context.args[0]
        resource_ids = context.args[1:] if len(context.args) > 1 else []
        
        try:
            # If no specific IDs provided, use smart selection
            if not resource_ids:
                resource_ids = await self._smart_select_resources_for_archive(archive_name)
            
            archive_id = self.storage.create_archive(
                name=archive_name,
                resource_ids=resource_ids,
                user_id=update.effective_user.id,
                username=update.effective_user.username
            )
            
            await update.message.reply_text(
                f"üì¶ **Archive created successfully!**\n\n"
                f"üìÇ **Name:** {archive_name}\n"
                f"üìä **Resources:** {len(resource_ids)}\n"
                f"üÜî **ID:** {archive_id}\n\n"
                f"üì¶ **–ê—Ä—Ö–∏–≤ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!**\n"
                f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `/export_archive {archive_id}` –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è",
                parse_mode=ParseMode.MARKDOWN
            )
            
        except Exception as e:
            logger.error(f"Error creating archive: {e}")
            await update.message.reply_text(
                "‚ùå Error creating archive. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
    
    async def find_folder_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Find folders and archives by name or content."""
        if not context.args:
            await update.message.reply_text(
                "üîç **Usage:** `/find_folder <search_query>`\n"
                "üîç **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** `/find_folder <–ø–æ–∏—Å–∫–æ–≤—ã–π_–∑–∞–ø—Ä–æ—Å>`\n\n"
                "**Examples / –ü—Ä–∏–º–µ—Ä—ã:**\n"
                "‚Ä¢ `/find_folder react`\n"
                "‚Ä¢ `/find_folder –¥–∏–∑–∞–π–Ω`\n"
                "‚Ä¢ `/find_folder web development`"
            )
            return
        
        query = ' '.join(context.args)
        
        try:
            folders = self.storage.find_folders(query)
            archives = self.storage.find_archives(query)
            
            if folders or archives:
                response = f"üîç **Search Results for '{query}':**\n\n"
                
                if folders:
                    response += "üìÅ **Folders:**\n"
                    for folder in folders[:5]:
                        response += f"‚Ä¢ {folder['name']} - {folder['description'][:50]}...\n"
                        response += f"  üÜî ID: {folder['id']} | üìä Items: {folder.get('item_count', 0)}\n\n"
                
                if archives:
                    response += "üì¶ **Archives:**\n"
                    for archive in archives[:5]:
                        response += f"‚Ä¢ {archive['name']} - {archive.get('description', 'Archive')[:50]}...\n"
                        response += f"  üÜî ID: {archive['id']} | üìä Items: {len(archive.get('resource_ids', []))}\n\n"
                
                await update.message.reply_text(response, parse_mode=ParseMode.MARKDOWN)
            else:
                await update.message.reply_text(
                    f"‚ùå No folders or archives found for '{query}'.\n"
                    f"‚ùå –ü–∞–ø–∫–∏ –∏–ª–∏ –∞—Ä—Ö–∏–≤—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
                )
                
        except Exception as e:
            logger.error(f"Error finding folders: {e}")
            await update.message.reply_text(
                "‚ùå Search error. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
    
    async def smart_search_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Enhanced search with AI-powered understanding."""
        if not context.args:
            await update.message.reply_text(
                "üß† **Usage:** `/smart_search <natural_language_query>`\n"
                "üß† **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** `/smart_search <–∑–∞–ø—Ä–æ—Å_–Ω–∞_–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º_—è–∑—ã–∫–µ>`\n\n"
                "**Examples / –ü—Ä–∏–º–µ—Ä—ã:**\n"
                "‚Ä¢ `/smart_search –Ω–∞–π–¥–∏ –≤—Å–µ React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å —Ö—É–∫–∞–º–∏`\n"
                "‚Ä¢ `/smart_search show me Python tutorials for beginners`\n"
                "‚Ä¢ `/smart_search –¥–∏–∑–∞–π–Ω —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π`"
            )
            return
        
        query = ' '.join(context.args)
        
        try:
            # Show processing indicator
            status_msg = await update.message.reply_text("üß† Analyzing query / –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–ø—Ä–æ—Å...")
            
            # Use AI to understand and enhance the query
            enhanced_query = await self._enhance_search_query(query)
            
            # Perform enhanced search
            results = await self._perform_smart_search(enhanced_query)
            
            await status_msg.delete()
            
            if results:
                response = f"üß† **Smart Search Results for '{query}':**\n\n"
                
                for i, result in enumerate(results[:8], 1):
                    relevance = result.get('relevance_score', 0.0)
                    response += (
                        f"{i}. **{result['category']}** - {result['description'][:80]}...\n"
                        f"   üéØ Relevance: {relevance:.1f}/10 | üÜî ID: {result['id']}\n\n"
                    )
                
                if len(results) > 8:
                    response += f"... and {len(results) - 8} more results\n\n"
                
                response += f"üìä Found {len(results)} relevant results"
                
                await update.message.reply_text(response, parse_mode=ParseMode.MARKDOWN)
            else:
                await update.message.reply_text(
                    f"‚ùå No relevant results found for '{query}'.\n"
                    f"‚ùå –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
                )
                
        except Exception as e:
            logger.error(f"Error in smart search: {e}")
            await update.message.reply_text(
                "‚ùå Smart search error. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
    
    async def analyze_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Analyze and provide insights about stored content."""
        try:
            # Show processing indicator
            status_msg = await update.message.reply_text("üìä Analyzing content / –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∫–æ–Ω—Ç–µ–Ω—Ç...")
            
            # Get comprehensive analysis
            analysis = await self._perform_content_analysis()
            
            await status_msg.delete()
            
            response = (
                "üìä **Content Analysis / –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞:**\n\n"
                f"üìÇ **Total Resources / –í—Å–µ–≥–æ —Ä–µ—Å—É—Ä—Å–æ–≤:** {analysis['total_resources']}\n"
                f"üè∑Ô∏è **Categories / –ö–∞—Ç–µ–≥–æ—Ä–∏–π:** {analysis['total_categories']}\n"
                f"üìÅ **Folders / –ü–∞–ø–æ–∫:** {analysis['total_folders']}\n"
                f"üì¶ **Archives / –ê—Ä—Ö–∏–≤–æ–≤:** {analysis['total_archives']}\n\n"
            )
            
            # Top categories
            if analysis.get('top_categories'):
                response += "üîù **Top Categories / –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:**\n"
                for category, count in analysis['top_categories'][:5]:
                    response += f"‚Ä¢ {category}: {count}\n"
                response += "\n"
            
            # Technology insights
            if analysis.get('technologies'):
                response += "üíª **Technologies Found / –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**\n"
                for tech, count in analysis['technologies'][:8]:
                    response += f"‚Ä¢ {tech}: {count}\n"
                response += "\n"
            
            # Recommendations
            if analysis.get('recommendations'):
                response += "üí° **Recommendations / –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**\n"
                for rec in analysis['recommendations'][:3]:
                    response += f"‚Ä¢ {rec}\n"
            
            await update.message.reply_text(response, parse_mode=ParseMode.MARKDOWN)
            
        except Exception as e:
            logger.error(f"Error in analysis: {e}")
            await update.message.reply_text(
                "‚ùå Analysis error. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )

    async def handle_photo(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle photo messages."""
        try:
            # Get photo and caption
            photo = update.message.photo[-1]  # Get highest resolution
            caption = update.message.caption or "Image without description"
            
            # Download photo
            file = await context.bot.get_file(photo.file_id)
            file_path = f"temp_image_{photo.file_id}.jpg"
            await file.download_to_drive(file_path)
            
            try:
                # Process image with file handler
                image_analysis = await self.file_handler.process_image(file_path, caption)
                
                # Combine caption and analysis
                content = f"{caption}\n\nImage analysis: {image_analysis}"
                
                # Process as regular content
                await self._process_content(update, context, content)
                
            finally:
                # Clean up
                if os.path.exists(file_path):
                    os.remove(file_path)
                    
        except Exception as e:
            logger.error(f"Error handling photo: {e}")
            await update.message.reply_text(
                "‚ùå Failed to process image / –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
            )
    
    async def handle_document(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle document messages."""
        try:
            document = update.message.document
            caption = update.message.caption or "Document without description"
            
            # Check file size (limit to 20MB)
            if document.file_size > 20 * 1024 * 1024:
                await update.message.reply_text(
                    "‚ùå File too large (max 20MB) / –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å 20–ú–ë)"
                )
                return
            
            # Download document
            file = await context.bot.get_file(document.file_id)
            file_path = f"temp_doc_{document.file_id}_{document.file_name}"
            await file.download_to_drive(file_path)
            
            try:
                # Process document with file handler
                doc_analysis = await self.file_handler.process_document(file_path, caption)
                
                # Combine caption and analysis
                content = f"{caption}\n\nDocument: {document.file_name}\nSize: {document.file_size} bytes\nAnalysis: {doc_analysis}"
                
                # Process as regular content
                await self._process_content(update, context, content)
                
            finally:
                # Clean up
                if os.path.exists(file_path):
                    os.remove(file_path)
                    
        except Exception as e:
            logger.error(f"Error handling document: {e}")
            await update.message.reply_text(
                "‚ùå Failed to process document / –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç"
            )
    
    async def handle_callback_query(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle callback queries from inline keyboards."""
        query = update.callback_query
        await query.answer()
        
        # Handle different callback types
        if query.data.startswith('view_'):
            resource_id = query.data.split('_')[1]
            await self._show_resource_details(query, resource_id)
        elif query.data.startswith('delete_'):
            resource_id = query.data.split('_')[1]
            await self._delete_resource(query, resource_id)
    
    async def _show_resource_details(self, query, resource_id: str):
        """Show detailed information about a resource."""
        try:
            resource = self.storage.get_resource(resource_id)
            if resource:
                response = (
                    f"üìÑ **Resource Details:**\n\n"
                    f"üÜî **ID:** {resource['id']}\n"
                    f"üìÇ **Category:** {resource['category']}\n"
                    f"üìù **Description:** {resource['description']}\n"
                    f"üìÖ **Created:** {resource['created_at']}\n\n"
                    f"üìÑ **Content:**\n{resource['content'][:500]}..."
                )
                
                await query.edit_message_text(response, parse_mode=ParseMode.MARKDOWN)
            else:
                await query.edit_message_text("‚ùå Resource not found")
                
        except Exception as e:
            logger.error(f"Error showing resource details: {e}")
            await query.edit_message_text("‚ùå Error retrieving resource")
    
    async def _delete_resource(self, query, resource_id: str):
        """Delete a resource."""
        try:
            success = self.storage.delete_resource(resource_id)
            if success:
                await query.edit_message_text("‚úÖ Resource deleted successfully")
            else:
                await query.edit_message_text("‚ùå Failed to delete resource")
                
        except Exception as e:
            logger.error(f"Error deleting resource: {e}")
            await query.edit_message_text("‚ùå Error deleting resource")
    
    async def _smart_select_resources_for_archive(self, archive_name: str) -> list:
        """Smart selection of resources for archive based on name."""
        try:
            # Extract keywords from archive name
            keywords = archive_name.lower().replace('_', ' ').split()
            
            # Search for relevant resources
            all_resources = self.storage.get_all_resources()
            selected = []
            
            for resource in all_resources:
                score = 0
                content_lower = resource['content'].lower()
                desc_lower = resource['description'].lower()
                category_lower = resource['category'].lower()
                
                # Score based on keyword matches
                for keyword in keywords:
                    if keyword in content_lower:
                        score += 3
                    if keyword in desc_lower:
                        score += 2
                    if keyword in category_lower:
                        score += 4
                
                # Include if score is high enough
                if score >= 2:
                    selected.append(resource['id'])
            
            # Limit to 20 most recent if too many
            if len(selected) > 20:
                selected = selected[-20:]
            
            return selected
            
        except Exception as e:
            logger.error(f"Error in smart resource selection: {e}")
            return []
    
    async def _enhance_search_query(self, query: str) -> dict:
        """Use AI to enhance and understand search query."""
        try:
            # Create enhanced prompt for query understanding
            prompt = f"""
Analyze this search query and extract key information:
Query: "{query}"

Provide a JSON response with:
{{
    "keywords": ["list", "of", "key", "terms"],
    "categories": ["relevant", "categories"],
    "technologies": ["mentioned", "technologies"],
    "intent": "what user is looking for",
    "language": "detected language (en/ru)",
    "filters": {{
        "file_types": ["if", "specific", "types"],
        "difficulty": "beginner/intermediate/advanced or null",
        "recency": "recent/old or null"
    }}
}}

Focus on web development, design, programming topics.
"""
            
            # Try to get AI enhancement
            if self.classifier.groq_client:
                response = await self.classifier._call_groq_api(prompt)
                if response and 'keywords' in response:
                    return response
            
            # Fallback to simple keyword extraction
            return {
                "keywords": query.lower().split(),
                "categories": [],
                "technologies": self._extract_technologies_from_text(query),
                "intent": "search",
                "language": "ru" if any(ord(c) > 127 for c in query) else "en",
                "filters": {}
            }
            
        except Exception as e:
            logger.error(f"Error enhancing search query: {e}")
            return {"keywords": query.lower().split(), "categories": [], "technologies": [], "intent": "search", "language": "en", "filters": {}}
    
    async def _perform_smart_search(self, enhanced_query: dict) -> list:
        """Perform enhanced search using AI-processed query."""
        try:
            all_resources = self.storage.get_all_resources()
            scored_results = []
            
            keywords = enhanced_query.get('keywords', [])
            categories = enhanced_query.get('categories', [])
            technologies = enhanced_query.get('technologies', [])
            
            for resource in all_resources:
                score = 0
                content_lower = resource['content'].lower()
                desc_lower = resource['description'].lower()
                category_lower = resource['category'].lower()
                
                # Keyword matching
                for keyword in keywords:
                    if keyword in content_lower:
                        score += 2
                    if keyword in desc_lower:
                        score += 3
                    if keyword in category_lower:
                        score += 4
                
                # Category matching
                for category in categories:
                    if category.lower() in category_lower:
                        score += 5
                
                # Technology matching
                for tech in technologies:
                    if tech.lower() in content_lower or tech.lower() in desc_lower:
                        score += 3
                
                # URL bonus for web development content
                if any(url_indicator in content_lower for url_indicator in ['http', 'www', '.com', '.org', 'github']):
                    score += 1
                
                if score > 0:
                    # Calculate relevance score (0-10)
                    relevance = min(10, score)
                    
                    result = resource.copy()
                    result['relevance_score'] = relevance
                    scored_results.append(result)
            
            # Sort by relevance score
            scored_results.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            return scored_results
            
        except Exception as e:
            logger.error(f"Error in smart search: {e}")
            return []
    
    async def _perform_content_analysis(self) -> dict:
        """Perform comprehensive analysis of stored content."""
        try:
            all_resources = self.storage.get_all_resources()
            folders = self.storage.get_all_folders()
            archives = self.storage.get_all_archives()
            
            # Basic statistics
            analysis = {
                'total_resources': len(all_resources),
                'total_categories': len(set(r['category'] for r in all_resources)),
                'total_folders': len(folders),
                'total_archives': len(archives)
            }
            
            # Category analysis
            category_counts = {}
            for resource in all_resources:
                category = resource['category']
                category_counts[category] = category_counts.get(category, 0) + 1
            
            analysis['top_categories'] = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)
            
            # Technology analysis
            tech_counts = {}
            tech_patterns = {
                'React': ['react', 'jsx', 'hooks'],
                'Vue': ['vue', 'vuejs'],
                'Angular': ['angular', 'typescript'],
                'Python': ['python', 'django', 'flask'],
                'JavaScript': ['javascript', 'js', 'node'],
                'CSS': ['css', 'sass', 'scss'],
                'HTML': ['html', 'html5'],
                'Docker': ['docker', 'container'],
                'Git': ['git', 'github', 'gitlab'],
                'API': ['api', 'rest', 'graphql'],
                'Database': ['sql', 'mongodb', 'postgres'],
                'Design': ['figma', 'sketch', 'ui', 'ux']
            }
            
            for resource in all_resources:
                content_lower = resource['content'].lower()
                for tech, patterns in tech_patterns.items():
                    if any(pattern in content_lower for pattern in patterns):
                        tech_counts[tech] = tech_counts.get(tech, 0) + 1
            
            analysis['technologies'] = sorted(tech_counts.items(), key=lambda x: x[1], reverse=True)
            
            # Generate recommendations
            recommendations = []
            
            if analysis['total_resources'] > 50:
                recommendations.append("Consider creating more specific folders to organize your resources")
            
            if len(analysis['top_categories']) > 10:
                recommendations.append("You have many categories - consider consolidating similar ones")
            
            if any(count > 20 for _, count in analysis['top_categories'][:3]):
                recommendations.append("Create archives for your most popular categories")
            
            analysis['recommendations'] = recommendations
            
            return analysis
            
        except Exception as e:
            logger.error(f"Error in content analysis: {e}")
            return {'total_resources': 0, 'total_categories': 0, 'total_folders': 0, 'total_archives': 0}
    
    def _extract_technologies_from_text(self, text: str) -> list:
        """Extract technology names from text."""
        technologies = []
        text_lower = text.lower()
        
        tech_keywords = {
            'react', 'vue', 'angular', 'python', 'javascript', 'typescript',
            'css', 'html', 'sass', 'scss', 'node', 'express', 'django',
            'flask', 'docker', 'kubernetes', 'git', 'github', 'api', 'rest',
            'graphql', 'sql', 'mongodb', 'postgres', 'figma', 'sketch',
            'photoshop', 'illustrator', 'ui', 'ux', 'design', 'frontend',
            'backend', 'fullstack', 'mobile', 'ios', 'android', 'swift',
            'kotlin', 'java', 'c++', 'c#', 'php', 'ruby', 'go', 'rust'
        }
        
        for tech in tech_keywords:
            if tech in text_lower:
                technologies.append(tech.capitalize())
        
        return list(set(technologies))
    
    async def _delete_resource(self, query, resource_id: str):
        """Delete a resource."""
        try:
            success = self.storage.delete_resource(resource_id)
            if success:
                await query.edit_message_text("‚úÖ Resource deleted successfully")
            else:
                await query.edit_message_text("‚ùå Failed to delete resource")
                
        except Exception as e:
            logger.error(f"Error deleting resource: {e}")
            await query.edit_message_text("‚ùå Error deleting resource")
    
    def run(self):
        """Start the bot."""
        logger.info("Starting DevDataSorter bot...")
        try:
            # Create event loop if it doesn't exist
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        self.app.run_polling(drop_pending_updates=True)
        logger.info("Bot stopped")

    async def create_folder_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Create a virtual folder for organizing resources."""
        if not context.args:
            await update.message.reply_text(
                "üìÅ **Usage:** `/create_folder <folder_name> [description]`\n"
                "üìÅ **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** `/create_folder <–∏–º—è_–ø–∞–ø–∫–∏> [–æ–ø–∏—Å–∞–Ω–∏–µ]`\n\n"
                "**Examples / –ü—Ä–∏–º–µ—Ä—ã:**\n"
                "‚Ä¢ `/create_folder react_projects React –ø—Ä–æ–µ–∫—Ç—ã –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã`\n"
                "‚Ä¢ `/create_folder design_resources UI/UX –¥–∏–∑–∞–π–Ω —Ä–µ—Å—É—Ä—Å—ã`"
            )
            return
        
        folder_name = context.args[0]
        description = ' '.join(context.args[1:]) if len(context.args) > 1 else f"–ü–∞–ø–∫–∞ –¥–ª—è {folder_name}"
        
        try:
            # Create folder as a special resource
            folder_id = self.storage.create_folder(
                name=folder_name,
                description=description,
                user_id=update.effective_user.id,
                username=update.effective_user.username
            )
            
            await update.message.reply_text(
                f"üìÅ **Folder created successfully!**\n\n"
                f"üìÇ **Name:** {folder_name}\n"
                f"üìù **Description:** {description}\n"
                f"üÜî **ID:** {folder_id}\n\n"
                f"üìÅ **–ü–∞–ø–∫–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!**\n"
                f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `/add_to_folder {folder_id}` –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤",
                parse_mode=ParseMode.MARKDOWN
            )
            
        except Exception as e:
            logger.error(f"Error creating folder: {e}")
            await update.message.reply_text(
                "‚ùå Error creating folder. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–ø–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
    
    async def create_archive_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Create an archive from selected resources."""
        if not context.args:
            await update.message.reply_text(
                "üì¶ **Usage:** `/create_archive <archive_name> [resource_ids...]`\n"
                "üì¶ **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** `/create_archive <–∏–º—è_–∞—Ä—Ö–∏–≤–∞> [id_—Ä–µ—Å—É—Ä—Å–æ–≤...]`\n\n"
                "**Examples / –ü—Ä–∏–º–µ—Ä—ã:**\n"
                "‚Ä¢ `/create_archive web_dev_2024 abc123 def456 ghi789`\n"
                "‚Ä¢ `/create_archive react_components` (—Å–æ–∑–¥–∞—Å—Ç –∞—Ä—Ö–∏–≤ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö React —Ä–µ—Å—É—Ä—Å–æ–≤)"
            )
            return
        
        archive_name = context.args[0]
        resource_ids = context.args[1:] if len(context.args) > 1 else []
        
        try:
            # If no specific IDs provided, use smart selection
            if not resource_ids:
                resource_ids = await self._smart_select_resources_for_archive(archive_name)
            
            archive_id = self.storage.create_archive(
                name=archive_name,
                resource_ids=resource_ids,
                user_id=update.effective_user.id,
                username=update.effective_user.username
            )
            
            await update.message.reply_text(
                f"üì¶ **Archive created successfully!**\n\n"
                f"üìÇ **Name:** {archive_name}\n"
                f"üìä **Resources:** {len(resource_ids)}\n"
                f"üÜî **ID:** {archive_id}\n\n"
                f"üì¶ **–ê—Ä—Ö–∏–≤ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!**\n"
                f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `/export_archive {archive_id}` –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è",
                parse_mode=ParseMode.MARKDOWN
            )
            
        except Exception as e:
            logger.error(f"Error creating archive: {e}")
            await update.message.reply_text(
                "‚ùå Error creating archive. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
    
    async def find_folder_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Find folders and archives by name or content."""
        if not context.args:
            await update.message.reply_text(
                "üîç **Usage:** `/find_folder <search_query>`\n"
                "üîç **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** `/find_folder <–ø–æ–∏—Å–∫–æ–≤—ã–π_–∑–∞–ø—Ä–æ—Å>`\n\n"
                "**Examples / –ü—Ä–∏–º–µ—Ä—ã:**\n"
                "‚Ä¢ `/find_folder react`\n"
                "‚Ä¢ `/find_folder –¥–∏–∑–∞–π–Ω`\n"
                "‚Ä¢ `/find_folder web development`"
            )
            return
        
        query = ' '.join(context.args)
        
        try:
            folders = self.storage.find_folders(query)
            archives = self.storage.find_archives(query)
            
            if folders or archives:
                response = f"üîç **Search Results for '{query}':**\n\n"
                
                if folders:
                    response += "üìÅ **Folders:**\n"
                    for folder in folders[:5]:
                        response += f"‚Ä¢ {folder['name']} - {folder['description'][:50]}...\n"
                        response += f"  üÜî ID: {folder['id']} | üìä Items: {folder.get('item_count', 0)}\n\n"
                
                if archives:
                    response += "üì¶ **Archives:**\n"
                    for archive in archives[:5]:
                        response += f"‚Ä¢ {archive['name']} - {archive.get('description', 'Archive')[:50]}...\n"
                        response += f"  üÜî ID: {archive['id']} | üìä Items: {len(archive.get('resource_ids', []))}\n\n"
                
                await update.message.reply_text(response, parse_mode=ParseMode.MARKDOWN)
            else:
                await update.message.reply_text(
                    f"‚ùå No folders or archives found for '{query}'.\n"
                    f"‚ùå –ü–∞–ø–∫–∏ –∏–ª–∏ –∞—Ä—Ö–∏–≤—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
                )
                
        except Exception as e:
            logger.error(f"Error finding folders: {e}")
            await update.message.reply_text(
                "‚ùå Search error. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
    
    async def smart_search_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Enhanced search with AI-powered understanding."""
        if not context.args:
            await update.message.reply_text(
                "üß† **Usage:** `/smart_search <natural_language_query>`\n"
                "üß† **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** `/smart_search <–∑–∞–ø—Ä–æ—Å_–Ω–∞_–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º_—è–∑—ã–∫–µ>`\n\n"
                "**Examples / –ü—Ä–∏–º–µ—Ä—ã:**\n"
                "‚Ä¢ `/smart_search –Ω–∞–π–¥–∏ –≤—Å–µ React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å —Ö—É–∫–∞–º–∏`\n"
                "‚Ä¢ `/smart_search show me Python tutorials for beginners`\n"
                "‚Ä¢ `/smart_search –¥–∏–∑–∞–π–Ω —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π`"
            )
            return
        
        query = ' '.join(context.args)
        
        try:
            # Show processing indicator
            status_msg = await update.message.reply_text("üß† Analyzing query / –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–ø—Ä–æ—Å...")
            
            # Use AI to understand and enhance the query
            enhanced_query = await self._enhance_search_query(query)
            
            # Perform enhanced search
            results = await self._perform_smart_search(enhanced_query)
            
            await status_msg.delete()
            
            if results:
                response = f"üß† **Smart Search Results for '{query}':**\n\n"
                
                for i, result in enumerate(results[:8], 1):
                    relevance = result.get('relevance_score', 0.0)
                    response += (
                        f"{i}. **{result['category']}** - {result['description'][:80]}...\n"
                        f"   üéØ Relevance: {relevance:.1f}/10 | üÜî ID: {result['id']}\n\n"
                    )
                
                if len(results) > 8:
                    response += f"... and {len(results) - 8} more results\n\n"
                
                response += f"üìä Found {len(results)} relevant results"
                
                await update.message.reply_text(response, parse_mode=ParseMode.MARKDOWN)
            else:
                await update.message.reply_text(
                    f"‚ùå No relevant results found for '{query}'.\n"
                    f"‚ùå –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
                )
                
        except Exception as e:
            logger.error(f"Error in smart search: {e}")
            await update.message.reply_text(
                "‚ùå Smart search error. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
    
    async def analyze_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Analyze and provide insights about stored content."""
        try:
            # Show processing indicator
            status_msg = await update.message.reply_text("üìä Analyzing content / –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∫–æ–Ω—Ç–µ–Ω—Ç...")
            
            # Get comprehensive analysis
            analysis = await self._perform_content_analysis()
            
            await status_msg.delete()
            
            response = (
                "üìä **Content Analysis / –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞:**\n\n"
                f"üìÇ **Total Resources / –í—Å–µ–≥–æ —Ä–µ—Å—É—Ä—Å–æ–≤:** {analysis['total_resources']}\n"
                f"üè∑Ô∏è **Categories / –ö–∞—Ç–µ–≥–æ—Ä–∏–π:** {analysis['total_categories']}\n"
                f"üìÅ **Folders / –ü–∞–ø–æ–∫:** {analysis['total_folders']}\n"
                f"üì¶ **Archives / –ê—Ä—Ö–∏–≤–æ–≤:** {analysis['total_archives']}\n\n"
            )
            
            # Top categories
            if analysis.get('top_categories'):
                response += "üîù **Top Categories / –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:**\n"
                for category, count in analysis['top_categories'][:5]:
                    response += f"‚Ä¢ {category}: {count}\n"
                response += "\n"
            
            # Technology insights
            if analysis.get('technologies'):
                response += "üíª **Technologies Found / –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**\n"
                for tech, count in analysis['technologies'][:8]:
                    response += f"‚Ä¢ {tech}: {count}\n"
                response += "\n"
            
            # Recommendations
            if analysis.get('recommendations'):
                response += "üí° **Recommendations / –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**\n"
                for rec in analysis['recommendations'][:3]:
                    response += f"‚Ä¢ {rec}\n"
            
            await update.message.reply_text(response, parse_mode=ParseMode.MARKDOWN)
            
        except Exception as e:
            logger.error(f"Error in analysis: {e}")
            await update.message.reply_text(
                "‚ùå Analysis error. Please try again.\n"
                "‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )

    async def handle_photo(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle photo messages."""
        try:
            # Get photo and caption
            photo = update.message.photo[-1]  # Get highest resolution
            caption = update.message.caption or "Image without description"
            
            # Download photo
            file = await context.bot.get_file(photo.file_id)
            file_path = f"temp_image_{photo.file_id}.jpg"
            await file.download_to_drive(file_path)
            
            try:
                # Process image with file handler
                image_analysis = await self.file_handler.process_image(file_path, caption)
                
                # Combine caption and analysis
                content = f"{caption}\n\nImage analysis: {image_analysis}"
                
                # Process as regular content
                await self._process_content(update, context, content)
                
            finally:
                # Clean up
                if os.path.exists(file_path):
                    os.remove(file_path)
                    
        except Exception as e:
            logger.error(f"Error handling photo: {e}")
            await update.message.reply_text(
                "‚ùå Failed to process image / –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
            )
    
    async def handle_document(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle document messages."""
        try:
            document = update.message.document
            caption = update.message.caption or "Document without description"
            
            # Check file size (limit to 20MB)
            if document.file_size > 20 * 1024 * 1024:
                await update.message.reply_text(
                    "‚ùå File too large (max 20MB) / –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å 20–ú–ë)"
                )
                return
            
            # Download document
            file = await context.bot.get_file(document.file_id)
            file_path = f"temp_doc_{document.file_id}_{document.file_name}"
            await file.download_to_drive(file_path)
            
            try:
                # Process document with file handler
                doc_analysis = await self.file_handler.process_document(file_path, caption)
                
                # Combine caption and analysis
                content = f"{caption}\n\nDocument: {document.file_name}\nSize: {document.file_size} bytes\nAnalysis: {doc_analysis}"
                
                # Process as regular content
                await self._process_content(update, context, content)
                
            finally:
                # Clean up
                if os.path.exists(file_path):
                    os.remove(file_path)
                    
        except Exception as e:
            logger.error(f"Error handling document: {e}")
            await update.message.reply_text(
                "‚ùå Failed to process document / –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç"
            )
    
    async def handle_callback_query(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle callback queries from inline keyboards."""
        query = update.callback_query
        await query.answer()
        
        # Handle different callback types
        if query.data.startswith('view_'):
            resource_id = query.data.split('_')[1]
            await self._show_resource_details(query, resource_id)
        elif query.data.startswith('delete_'):
            resource_id = query.data.split('_')[1]
            await self._delete_resource(query, resource_id)
    
    async def _show_resource_details(self, query, resource_id: str):
        """Show detailed information about a resource."""
        try:
            resource = self.storage.get_resource(resource_id)
            if resource:
                response = (
                    f"üìÑ **Resource Details:**\n\n"
                    f"üÜî **ID:** {resource['id']}\n"
                    f"üìÇ **Category:** {resource['category']}\n"
                    f"üìù **Description:** {resource['description']}\n"
                    f"üìÖ **Created:** {resource['created_at']}\n\n"
                    f"üìÑ **Content:**\n{resource['content'][:500]}..."
                )
                
                await query.edit_message_text(response, parse_mode=ParseMode.MARKDOWN)
            else:
                await query.edit_message_text("‚ùå Resource not found")
                
        except Exception as e:
            logger.error(f"Error showing resource details: {e}")
            await query.edit_message_text("‚ùå Error retrieving resource")
    
    async def _delete_resource(self, query, resource_id: str):
        """Delete a resource."""
        try:
            success = self.storage.delete_resource(resource_id)
            if success:
                await query.edit_message_text("‚úÖ Resource deleted successfully")
            else:
                await query.edit_message_text("‚ùå Failed to delete resource")
                
        except Exception as e:
            logger.error(f"Error deleting resource: {e}")
            await query.edit_message_text("‚ùå Error deleting resource")
    
    async def _smart_select_resources_for_archive(self, archive_name: str) -> list:
        """Smart selection of resources for archive based on name."""
        try:
            # Extract keywords from archive name
            keywords = archive_name.lower().replace('_', ' ').split()
            
            # Search for relevant resources
            all_resources = self.storage.get_all_resources()
            selected = []
            
            for resource in all_resources:
                score = 0
                content_lower = resource['content'].lower()
                desc_lower = resource['description'].lower()
                category_lower = resource['category'].lower()
                
                # Score based on keyword matches
                for keyword in keywords:
                    if keyword in content_lower:
                        score += 3
                    if keyword in desc_lower:
                        score += 2
                    if keyword in category_lower:
                        score += 4
                
                # Include if score is high enough
                if score >= 2:
                    selected.append(resource['id'])
            
            # Limit to 20 most recent if too many
            if len(selected) > 20:
                selected = selected[-20:]
            
            return selected
            
        except Exception as e:
            logger.error(f"Error in smart resource selection: {e}")
            return []
    
    async def _enhance_search_query(self, query: str) -> dict:
        """Use AI to enhance and understand search query."""
        try:
            # Create enhanced prompt for query understanding
            prompt = f"""
Analyze this search query and extract key information:
Query: "{query}"

Provide a JSON response with:
{{
    "keywords": ["list", "of", "key", "terms"],
    "categories": ["relevant", "categories"],
    "technologies": ["mentioned", "technologies"],
    "intent": "what user is looking for",
    "language": "detected language (en/ru)",
    "filters": {{
        "file_types": ["if", "specific", "types"],
        "difficulty": "beginner/intermediate/advanced or null",
        "recency": "recent/old or null"
    }}
}}

Focus on web development, design, programming topics.
"""
            
            # Try to get AI enhancement
            if self.classifier.groq_client:
                response = await self.classifier._call_groq_api(prompt)
                if response and 'keywords' in response:
                    return response
            
            # Fallback to simple keyword extraction
            return {
                "keywords": query.lower().split(),
                "categories": [],
                "technologies": self._extract_technologies_from_text(query),
                "intent": "search",
                "language": "ru" if any(ord(c) > 127 for c in query) else "en",
                "filters": {}
            }
            
        except Exception as e:
            logger.error(f"Error enhancing search query: {e}")
            return {"keywords": query.lower().split(), "categories": [], "technologies": [], "intent": "search", "language": "en", "filters": {}}
    
    async def _perform_smart_search(self, enhanced_query: dict) -> list:
        """Perform enhanced search using AI-processed query."""
        try:
            all_resources = self.storage.get_all_resources()
            scored_results = []
            
            keywords = enhanced_query.get('keywords', [])
            categories = enhanced_query.get('categories', [])
            technologies = enhanced_query.get('technologies', [])
            
            for resource in all_resources:
                score = 0
                content_lower = resource['content'].lower()
                desc_lower = resource['description'].lower()
                category_lower = resource['category'].lower()
                
                # Keyword matching
                for keyword in keywords:
                    if keyword in content_lower:
                        score += 2
                    if keyword in desc_lower:
                        score += 3
                    if keyword in category_lower:
                        score += 4
                
                # Category matching
                for category in categories:
                    if category.lower() in category_lower:
                        score += 5
                
                # Technology matching
                for tech in technologies:
                    if tech.lower() in content_lower or tech.lower() in desc_lower:
                        score += 3
                
                # URL bonus for web development content
                if any(url_indicator in content_lower for url_indicator in ['http', 'www', '.com', '.org', 'github']):
                    score += 1
                
                if score > 0:
                    # Calculate relevance score (0-10)
                    relevance = min(10, score)
                    
                    result = resource.copy()
                    result['relevance_score'] = relevance
                    scored_results.append(result)
            
            # Sort by relevance score
            scored_results.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            return scored_results
            
        except Exception as e:
            logger.error(f"Error in smart search: {e}")
            return []
    
    async def _perform_content_analysis(self) -> dict:
        """Perform comprehensive analysis of stored content."""
        try:
            all_resources = self.storage.get_all_resources()
            folders = self.storage.get_all_folders()
            archives = self.storage.get_all_archives()
            
            # Basic statistics
            analysis = {
                'total_resources': len(all_resources),
                'total_categories': len(set(r['category'] for r in all_resources)),
                'total_folders': len(folders),
                'total_archives': len(archives)
            }
            
            # Category analysis
            category_counts = {}
            for resource in all_resources:
                category = resource['category']
                category_counts[category] = category_counts.get(category, 0) + 1
            
            analysis['top_categories'] = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)
            
            # Technology analysis
            tech_counts = {}
            tech_patterns = {
                'React': ['react', 'jsx', 'hooks'],
                'Vue': ['vue', 'vuejs'],
                'Angular': ['angular', 'typescript'],
                'Python': ['python', 'django', 'flask'],
                'JavaScript': ['javascript', 'js', 'node'],
                'CSS': ['css', 'sass', 'scss'],
                'HTML': ['html', 'html5'],
                'Docker': ['docker', 'container'],
                'Git': ['git', 'github', 'gitlab'],
                'API': ['api', 'rest', 'graphql'],
                'Database': ['sql', 'mongodb', 'postgres'],
                'Design': ['figma', 'sketch', 'ui', 'ux']
            }
            
            for resource in all_resources:
                content_lower = resource['content'].lower()
                for tech, patterns in tech_patterns.items():
                    if any(pattern in content_lower for pattern in patterns):
                        tech_counts[tech] = tech_counts.get(tech, 0) + 1
            
            analysis['technologies'] = sorted(tech_counts.items(), key=lambda x: x[1], reverse=True)
            
            # Generate recommendations
            recommendations = []
            
            if analysis['total_resources'] > 50:
                recommendations.append("Consider creating more specific folders to organize your resources")
            
            if len(analysis['top_categories']) > 10:
                recommendations.append("You have many categories - consider consolidating similar ones")
            
            if any(count > 20 for _, count in analysis['top_categories'][:3]):
                recommendations.append("Create archives for your most popular categories")
            
            analysis['recommendations'] = recommendations
            
            return analysis
            
        except Exception as e:
            logger.error(f"Error in content analysis: {e}")
            return {'total_resources': 0, 'total_categories': 0, 'total_folders': 0, 'total_archives': 0}
    
    def _extract_technologies_from_text(self, text: str) -> list:
        """Extract technology names from text."""
        technologies = []
        text_lower = text.lower()
        
        tech_keywords = {
            'react', 'vue', 'angular', 'python', 'javascript', 'typescript',
            'css', 'html', 'sass', 'scss', 'node', 'express', 'django',
            'flask', 'docker', 'kubernetes', 'git', 'github', 'api', 'rest',
            'graphql', 'sql', 'mongodb', 'postgres', 'figma', 'sketch',
            'photoshop', 'illustrator', 'ui', 'ux', 'design', 'frontend',
            'backend', 'fullstack', 'mobile', 'ios', 'android', 'swift',
            'kotlin', 'java', 'c++', 'c#', 'php', 'ruby', 'go', 'rust'
        }
        
        for tech in tech_keywords:
            if tech in text_lower:
                technologies.append(tech.capitalize())
        
        return list(set(technologies))